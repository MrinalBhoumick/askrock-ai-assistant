from __future__ import annotations

import json
import logging
import os
import time
import traceback
from datetime import datetime
from typing import List, Dict, Any, Optional

import boto3
import botocore.exceptions as boto_exc
import pyttsx3
import pytesseract
import speech_recognition as sr
import streamlit as st
from dotenv import load_dotenv
from PIL import Image

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. Logging & ENV â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(level=logging.INFO, format="%(levelname)s | %(message)s")
logger = logging.getLogger("AskRockAI")

load_dotenv()

# Configuration
AWS_REGION: str = os.getenv("AWS_REGION", "us-east-1")
MODEL_ID: str = os.getenv("BEDROCK_INFERENCE_PROFILE_ARN", "")
DEFAULT_MAX_RETRIES = 7
DEFAULT_RETRY_DELAY_SECONDS = 3
DEFAULT_MAX_TOKENS = 25000

ROLE_ARN = "arn:aws:iam::207567766326:role/Workmates-SSO-L2SupportRole"
SESSION_NAME = "AskRockAISession"

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. AWS client bootstrap â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_bedrock_client() -> boto3.client:  # type: ignore[return-value]
    """
    Return a Bedrock Runtime client after assuming **ROLE_ARN**.

    Raises
    ------
    streamlit.StopException
        If no base credentials are found, a Streamlit error is shown
        and the script is stopped.
    """
    try:
        # Assume the target IAM role using default boto3 credentials
        sts = boto3.client("sts", region_name=AWS_REGION)
        logger.info("Assuming role %s â€¦", ROLE_ARN)

        assumed = sts.assume_role(
            RoleArn=ROLE_ARN,
            RoleSessionName=SESSION_NAME,
            DurationSeconds=3600,
        )["Credentials"]

        # Return a bedrock-runtime client using the assumed temporary credentials
        return boto3.client(
            "bedrock-runtime",
            region_name=AWS_REGION,
            aws_access_key_id=assumed["AccessKeyId"],
            aws_secret_access_key=assumed["SecretAccessKey"],
            aws_session_token=assumed["SessionToken"],
        )

    except boto_exc.NoCredentialsError:
        msg = (
            "ğŸ›‘  No AWS credentials were found.\n\n"
            "Provide *any* base credentials via:\n"
            " â€¢ Environment vars AWS_ACCESS_KEY_ID / AWS_SECRET_ACCESS_KEY\n"
            " â€¢ An AWS profile (set AWS_PROFILE after `aws configure` or `aws sso login`)\n"
            " â€¢ An instance/Lambda/ECS role."
        )
        logger.error(msg)
        st.error(msg)
        st.stop()

    except boto_exc.ClientError as exc:
        logger.error("âŒ Failed to assume role: %s", exc)
        st.error(f"Unable to assume IAM role:\n{exc}")
        st.stop()

    except Exception as exc:
        logger.exception("Unexpected error while creating Bedrock client")
        st.error(f"Unexpected AWS error: {exc}")
        st.stop()


# Cache the client across reruns
bedrock_runtime = get_bedrock_client()
logger.info("Bedrock client initialised âœ”")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. Helper functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def microphone_available() -> bool:
    try:
        sr.Microphone()
        return True
    except OSError as e:
        logger.warning("Microphone check failed: %s", e)
        return False

def build_prompt(question: str, topic: str, ocr_text: str) -> str:
    prompt = f"Topic: {topic}\n\nQuestion: {question}"
    if ocr_text.strip():
        prompt += f"\n\nAdditional context extracted from image:\n{ocr_text.strip()}"
    return prompt

def format_output(text: str) -> str:
    return text.strip()

def speak_text(text: str) -> None:
    engine = pyttsx3.init()
    engine.setProperty("rate", 180)
    engine.say(text)
    engine.runAndWait()

def attempt_model_invoke(payload: Dict[str, Any], retries: int, delay: int) -> Optional[str]:
    last_exc: Optional[Exception] = None
    for attempt in range(1, retries + 1):
        try:
            logger.info("Attempt %d: sending request to Bedrock â€¦", attempt)
            start = time.time()
            response = bedrock_runtime.invoke_model(
                modelId=MODEL_ID,
                contentType="application/json",
                accept="application/json",
                body=json.dumps(payload).encode("utf-8"),
            )
            logger.info("Response in %.2fs", time.time() - start)
            raw = response["body"].read().decode("utf-8")
            logger.debug("Raw response: %s", raw)
            data = json.loads(raw)
            messages = data.get("content", [])
            if isinstance(messages, list) and messages:
                return messages[0].get("text", "").strip()
            logger.warning("Unexpected response structure: %s", data)
            return None
        except Exception as exc:
            logger.error("Attempt %d failed: %s", attempt, exc)
            last_exc = exc
            if attempt < retries:
                time.sleep(delay)
    if last_exc:
        raise last_exc
    return None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. UI â€“ Streamlit â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

st.set_page_config(page_title="ğŸª¨ğŸ™ï¸ AskRock AI with Chat", page_icon="ğŸª¨", layout="wide")
st.title("ğŸª¨ğŸ™ï¸ AskRock AI: Bedrock Chat Assistant")
st.caption("_Now with Chat History, Save, and Optional Image OCR!_")

# Sidebar settings
with st.sidebar:
    st.header("âš™ï¸ Settings")
    max_tokens = st.slider("Max tokens:", 500, 30000, DEFAULT_MAX_TOKENS, step=500)
    max_retries = st.slider("Max retries:", 1, 10, DEFAULT_MAX_RETRIES)
    retry_delay = st.slider("Retry delay (s):", 1, 10, DEFAULT_RETRY_DELAY_SECONDS)
    auto_speak = st.checkbox("ğŸ”Š Auto-read answer aloud", value=True)
    theme = st.radio("ğŸ¨ Theme:", ["Light", "Dark"], index=0)
    st.divider()

if theme == "Dark":
    st.markdown(
        """
        <style>
        body { background-color: #0e1117; color: #fafafa; }
        </style>
        """,
        unsafe_allow_html=True,
    )

topic = st.text_input("ğŸ” Optional topic (e.g., Finance, Science):", value="General")

col1, col2 = st.columns(2)

with col1:
    st.subheader("ğŸ’¬ Type your question")
    user_query = st.text_area(" ", placeholder="Enter your question hereâ€¦")

    st.subheader("ğŸ–¼ï¸ Optionally upload an image with your question")
    uploaded_image = st.file_uploader("Upload image", type=["jpg", "jpeg", "png"])
    extracted_text = ""
    if uploaded_image is not None:
        st.image(uploaded_image, caption="Uploaded Image", use_column_width=True)
        try:
            img = Image.open(uploaded_image)
            extracted_text = pytesseract.image_to_string(img)
            if extracted_text.strip():
                st.info(f"ğŸ“ Extracted text from image:\n\n{extracted_text.strip()}")
            else:
                st.warning("âš ï¸ No text could be extracted from the image.")
        except Exception as exc:
            st.error(f"Failed to parse image: {exc}")

with col2:
    st.subheader("ğŸ¤ Record your question")
    if microphone_available():
        if st.button("ğŸ™ï¸ Start Recording"):
            try:
                recognizer = sr.Recognizer()
                mic = sr.Microphone()
                with mic as source:
                    st.info("Listeningâ€¦ speak clearly.")
                    audio = recognizer.listen(source, timeout=10, phrase_time_limit=20)
                try:
                    text = recognizer.recognize_google(audio)
                    user_query = text
                    st.success(f"ğŸ“ Transcribed: {text}")
                except sr.UnknownValueError:
                    st.error("Could not understand audio. Please try again.")
                except sr.RequestError as exc:
                    st.error(f"Speech recognition error: {exc}")
            except OSError as exc:
                st.error("ğŸ¤ No microphone detected on this device/environment. Please use text input instead.")
                logger.error("Microphone init error: %s", exc)
    else:
        st.info("ğŸ¤ Microphone not available in this environment. Please use text input or upload an image.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5. Chat handling & history â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if "chat_history" not in st.session_state:
    st.session_state.chat_history: List[Dict[str, str]] = []  # type: ignore[assignment]

if st.button("ğŸš€ Get Answer"):
    if not user_query.strip() and not extracted_text.strip():
        st.error("Please type/record your question or upload an image with text.")
    else:
        combined_prompt = build_prompt(user_query, topic, extracted_text)
        with st.expander("ğŸ” Prompt Details"):
            st.code(combined_prompt, language="markdown")
        payload = {
            "anthropic_version": "bedrock-2023-05-31",
            "max_tokens": max_tokens,
            "messages": [{"role": "user", "content": combined_prompt}],
        }
        try:
            with st.spinner("Thinkingâ€¦ â³"):
                answer = attempt_model_invoke(payload, max_retries, retry_delay)
            if answer:
                formatted = format_output(answer)
                st.success("âœ… **Answer:**")
                st.markdown(f"### {formatted}")
                st.session_state.chat_history.append({
                    "question": user_query or "[Image-only question]",
                    "answer": formatted,
                })
                if auto_speak:
                    speak_text(formatted)
            else:
                st.error("âš ï¸ No response received after retries.")
        except Exception as exc:
            st.error(f"âŒ Error: {exc}")
            st.text(traceback.format_exc())

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 6. Display chat history â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if st.session_state.chat_history:
    st.markdown("---")
    st.header("ğŸ—‚ï¸ Chat History")
    for i, entry in enumerate(reversed(st.session_state.chat_history), 1):
        st.markdown(f"**Q{i}:** {entry['question']}")
        st.markdown(f"**A{i}:** {entry['answer']}")

    if st.download_button(
        label="ğŸ’¾ Download Chat History",
        data="\n\n".join(f"Q: {e['question']}\nA: {e['answer']}" for e in st.session_state.chat_history),
        file_name=f"askrock_chat_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
        mime="text/plain",
    ):
        st.success("âœ… Chat history saved successfully!")
